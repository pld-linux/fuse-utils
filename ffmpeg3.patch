diff -ur fuse-utils-1.1.1.orig/config.h.in fuse-utils-1.1.1/config.h.in
--- fuse-utils-1.1.1.orig/config.h.in	2016-04-04 21:22:30.888884415 +0900
+++ fuse-utils-1.1.1/config.h.in	2016-04-04 21:36:36.647545989 +0900
@@ -39,6 +39,9 @@
 /* Define to 1 if you have the <libavformat/avformat.h> header file. */
 #undef HAVE_LIBAVFORMAT_AVFORMAT_H
 
+/* Define to 1 if you have the <libavresample/avresample.h> header file. */
+#undef HAVE_LIBAVRESAMPLE_AVRESAMPLE_H
+
 /* Define to 1 if you have the <libspectrum.h> header file. */
 #undef HAVE_LIBSPECTRUM_H
 
diff -ur fuse-utils-1.1.1.orig/configure.ac fuse-utils-1.1.1/configure.ac
--- fuse-utils-1.1.1.orig/configure.ac	2013-05-25 05:57:58.000000000 +0900
+++ fuse-utils-1.1.1/configure.ac	2016-04-04 21:36:21.310466771 +0900
@@ -85,8 +85,8 @@
 AC_MSG_RESULT($ffmpeglib)
 if test "$ffmpeglib" = yes; then
   AC_CHECK_HEADERS(
-    libavformat/avformat.h libswscale/swscale.h,
-    FFMPEG_LIBS="-lavformat -lavcodec -lswscale -lavutil",
+    libavformat/avformat.h libswscale/swscale.h libavresample/avresample.h,
+    FFMPEG_LIBS="-lavformat -lavcodec -lswscale -lavresample -lavutil",
     FFMPEG_LIBS=''; break
   )
   if test "x$FFMPEG_LIBS" != "x"
diff -ur fuse-utils-1.1.1.orig/fmfconv_ff.c fuse-utils-1.1.1/fmfconv_ff.c
--- fuse-utils-1.1.1.orig/fmfconv_ff.c	2016-04-04 21:22:23.562038706 +0900
+++ fuse-utils-1.1.1/fmfconv_ff.c	2016-04-04 21:36:21.310466771 +0900
@@ -60,13 +60,16 @@
 
 #include <libavformat/avformat.h>
 #include <libavutil/mathematics.h>
+#include <libavutil/opt.h>
+#include <libavresample/avresample.h>
 #include <libswscale/swscale.h>
+#include <libpostproc/postprocess.h>
 
 #include "libspectrum.h"
 #include "fmfconv.h"
 
 #define VRATE_MULT 2
-static int sws_flags = SWS_BICUBIC | SWS_CPU_CAPS_3DNOW | SWS_CPU_CAPS_MMX2;
+static int sws_flags = SWS_BICUBIC | PP_CPU_CAPS_3DNOW | PP_CPU_CAPS_MMX2;
 
 int ffmpeg_arate = 0;		/* audio bitrate */
 int ffmpeg_vrate = 0;		/* video bitrate */
@@ -94,17 +97,18 @@
 static int audio_inpbuf_len;			/* actual number of audio frames */
 
 static AVFrame *ff_picture, *ff_tmp_picture, *ffmpeg_pict;
+static AVFrame *audio_frame;
 static struct SwsContext *video_resize_ctx;
 
-static ReSampleContext *audio_resample_ctx;
+static AVAudioResampleContext *audio_resample_ctx;
 static int16_t **ffmpeg_sound;
 
 static uint8_t *video_outbuf;
 static int video_outbuf_size;
 
-static AVFrame *alloc_picture( enum PixelFormat pix_fmt, int width, int height, void *fmf_pict );
+static AVFrame *alloc_picture( enum AVPixelFormat pix_fmt, int width, int height, void *fmf_pict );
 
-static enum PixelFormat out_pix_fmt = PIX_FMT_NONE;
+static enum AVPixelFormat out_pix_fmt = AV_PIX_FMT_NONE;
 /* FFMPEG utility functions */
 
 static int res_rte = -1;
@@ -130,11 +134,10 @@
 int
 ffmpeg_resample_audio( void )
 {
-  int len;
+  int len, ret;
 
   if( audio_resample_ctx && res_rte != snd_rte ) {
-    audio_resample_close( audio_resample_ctx );
-    audio_resample_ctx = NULL;
+    avresample_free( &audio_resample_ctx );
     av_free( audio_tmp_inpbuf );
     ffmpeg_sound = &sound16;
     printi( 2, "ffmpeg_resample_audio(): reinit resample %dHz -> %dHz\n", snd_rte, out_rte );
@@ -145,11 +148,20 @@
     out_fsz = 2 * out_chn;
   }
   if( !audio_resample_ctx ) {
-    audio_resample_ctx = av_audio_resample_init( out_chn, snd_chn,
-						 out_rte, snd_rte,
-						 AV_SAMPLE_FMT_S16,
-                                                 AV_SAMPLE_FMT_S16,
-						 16, 8, 1, 1.0 );
+    audio_resample_ctx = avresample_alloc_context();
+    av_opt_set_int(audio_resample_ctx, "in_channel_layout",  av_get_default_channel_layout(snd_chn), 0);
+    av_opt_set_int(audio_resample_ctx, "out_channel_layout", av_get_default_channel_layout(out_chn), 0);
+    av_opt_set_int(audio_resample_ctx, "in_sample_fmt",      AV_SAMPLE_FMT_S16,			     0);
+    av_opt_set_int(audio_resample_ctx, "out_sample_fmt",     AV_SAMPLE_FMT_S16,		             0);
+    av_opt_set_int(audio_resample_ctx, "in_sample_rate",     snd_rte,		                     0);
+    av_opt_set_int(audio_resample_ctx, "out_sample_rate",    out_rte,		                     0);
+
+    ret = avresample_open(audio_resample_ctx);
+    if (ret < 0) {
+        printe( "Error opening the resample context\n");
+        return 1;
+    }
+
     audio_tmp_inpbuf_size = (float)audio_outbuf_size * out_rte / snd_rte * (float)out_chn / snd_chn + 1.0;
     audio_tmp_inpbuf = av_malloc( audio_tmp_inpbuf_size );
     ffmpeg_sound = (void *)(&audio_tmp_inpbuf);
@@ -160,9 +172,9 @@
     return 1;
   }
 
-  len = audio_resample( audio_resample_ctx,
-                  (short *)audio_tmp_inpbuf, (short *)sound16,
-                  snd_len / snd_fsz );
+  len = avresample_convert( audio_resample_ctx,
+                  (uint8_t**)&audio_tmp_inpbuf, audio_tmp_inpbuf_size, audio_tmp_inpbuf_size / out_fsz,
+		  (uint8_t**)&sound16, snd_len, snd_len / snd_fsz );
   if( !len ) {
     printe( "FFMPEG: Error during audio resampling\n" );
     return 1;
@@ -198,7 +210,7 @@
   }
   if( video_resize_ctx == NULL ) {
     video_resize_ctx = sws_getContext( res_w, res_h,
-                                      PIX_FMT_YUV444P,
+                                      AV_PIX_FMT_YUV444P,
                                       out_w, out_h,
                                       out_pix_fmt,
                                       sws_flags, NULL, NULL, NULL );
@@ -213,7 +225,7 @@
   sws_scale( video_resize_ctx, 
 		(const uint8_t * const*)ff_picture->data, ff_picture->linesize,
 		0, res_h, ff_tmp_picture->data, ff_tmp_picture->linesize );
-  printi( 3, "ffmpeg_rescale_frame(): resize %dx%d -> %dx%d pix format %d->%d\n", frm_w, frm_h, out_w, out_h, PIX_FMT_YUV444P, out_pix_fmt );
+  printi( 3, "ffmpeg_rescale_frame(): resize %dx%d -> %dx%d pix format %d->%d\n", frm_w, frm_h, out_w, out_h, AV_PIX_FMT_YUV444P, out_pix_fmt );
   return 0;
 }
 
@@ -295,6 +307,8 @@
 #endif
   audio_input_frames = c->frame_size;
 
+  audio_frame = av_frame_alloc();
+
   if( audio_input_frames <= 1 ) {
     audio_outbuf_size = out_rte * 1250 * audio_oframe_size / out_fps;
   } else {
@@ -336,20 +350,25 @@
   if( audio_input_frames > 1 ) {
      while( audio_inpbuf_len + len >= audio_input_frames ) {
       int copy_len = ( audio_input_frames - audio_inpbuf_len ) * audio_iframe_size;
-      AVPacket pkt;
-      av_init_packet( &pkt );
+      AVPacket pkt = { 0 };
+      int ret, got_output;
 
       memcpy( (char *)audio_inpbuf + ( audio_inpbuf_len * audio_iframe_size ), buf, copy_len );
       len -= audio_input_frames - audio_inpbuf_len;
       buf = (void *)( (char *)buf + copy_len );
 
-      pkt.size = avcodec_encode_audio( c, audio_outbuf, audio_outbuf_size, audio_inpbuf );
+      audio_frame->data[0] = audio_inpbuf;
+      audio_frame->linesize[0] = c->frame_size * audio_iframe_size;
+      audio_frame->nb_samples = c->frame_size;
+
+      ret = avcodec_encode_audio2( c, &pkt, audio_frame, &got_output);
+
+      if (!got_output)
+          continue;
 
       if( c->coded_frame && c->coded_frame->pts != AV_NOPTS_VALUE )
 	pkt.pts= av_rescale_q( c->coded_frame->pts, c->time_base, audio_st->time_base );
-      pkt.flags |= AV_PKT_FLAG_KEY;
       pkt.stream_index = audio_st->index;
-      pkt.data = audio_outbuf;
 
     /* write the compressed frame in the media file */
       if( av_interleaved_write_frame( oc, &pkt ) != 0 ) {
@@ -365,21 +384,25 @@
 
 
   } else {			/* with PCM output */
-    AVPacket pkt;
-    av_init_packet( &pkt );
-
-    pkt.size = avcodec_encode_audio( c, audio_outbuf, coded_bps ? len * out_chn * coded_bps / 8 : len * out_chn, buf );
-
-    if( c->coded_frame && c->coded_frame->pts != AV_NOPTS_VALUE )
-      pkt.pts= av_rescale_q( c->coded_frame->pts, c->time_base, audio_st->time_base );
-    pkt.flags |= AV_PKT_FLAG_KEY;
-    pkt.stream_index = audio_st->index;
-    pkt.data = audio_outbuf;
+    AVPacket pkt = { 0 };
+    int ret, got_output;
 
-    /* write */
-    if( av_interleaved_write_frame( oc, &pkt ) != 0 ) {
-      fprintf( stderr, "Error while writing audio frame\n" );
-/*      exit( 1 ); */
+    audio_frame->data[0] = buf;
+    audio_frame->linesize[0] = c->frame_size * audio_iframe_size;
+    audio_frame->nb_samples = c->frame_size;
+
+    ret = avcodec_encode_audio2( c, &pkt, audio_frame, &got_output);
+
+    if (got_output) {
+        if( c->coded_frame && c->coded_frame->pts != AV_NOPTS_VALUE )
+          pkt.pts= av_rescale_q( c->coded_frame->pts, c->time_base, audio_st->time_base );
+        pkt.stream_index = audio_st->index;
+
+        /* write */
+        if( av_interleaved_write_frame( oc, &pkt ) != 0 ) {
+          fprintf( stderr, "Error while writing audio frame\n" );
+    /*      exit( 1 ); */
+        }
     }
     printi( 3, "ffmpeg_add_sound_ffmpeg(): write sound packet %d samples pkt.size = %dbyte\n", len, pkt.size );
   }
@@ -419,6 +442,7 @@
 {
   if( audio_st ) avcodec_close( audio_st->codec );
   if( audio_outbuf ) av_free( audio_outbuf );
+  av_frame_free(&audio_frame);
 }
 
 /**************************************************************/
@@ -499,13 +523,13 @@
 }
 
 static AVFrame *
-alloc_picture( enum PixelFormat pix_fmt, int width, int height, void *fmf_pict )
+alloc_picture( enum AVPixelFormat pix_fmt, int width, int height, void *fmf_pict )
 {
   AVFrame *picture;
   uint8_t *picture_buf;
   int size;
 
-  picture = avcodec_alloc_frame();
+  picture = av_frame_alloc();
   if( !picture ) return NULL;
   if( !fmf_pict ) {
     size = avpicture_get_size( pix_fmt, width, height );
@@ -532,7 +556,7 @@
   c = video_st->codec;
 
   if( codec->pix_fmts == NULL )
-     c->pix_fmt = PIX_FMT_YUV420P;
+     c->pix_fmt = AV_PIX_FMT_YUV420P;
   else
     c->pix_fmt = codec->pix_fmts[0];
 
@@ -583,7 +607,7 @@
   }
 
   /* allocate the encoded raw picture */
-  ff_picture = alloc_picture( PIX_FMT_YUV444P, frm_w, frm_h, pix_yuv[0] );
+  ff_picture = alloc_picture( AV_PIX_FMT_YUV444P, frm_w, frm_h, pix_yuv[0] );
   ff_tmp_picture = NULL;
 
   if( !ff_picture ) {
@@ -599,7 +623,7 @@
 void
 ffmpeg_add_frame_ffmpeg( void )
 {
-  int out_size, ret;
+  int got_output, ret;
   AVCodecContext *c;
 
   if( !video_st ) return;
@@ -619,22 +643,17 @@
 
     ret = av_interleaved_write_frame( oc, &pkt );
   } else {
+    AVPacket pkt = { 0 };
+
     ffmpeg_pict->pts = c->frame_number;
 
         /* encode the image */
-    out_size = avcodec_encode_video( c, video_outbuf, video_outbuf_size, ffmpeg_pict );
-        /* if zero size, it means the image was buffered */
-    if( out_size > 0 ) {
-      AVPacket pkt;
-      av_init_packet( &pkt );
-
-      if( c->coded_frame->pts != AV_NOPTS_VALUE )
-        pkt.pts = av_rescale_q( c->coded_frame->pts, c->time_base, video_st->time_base );
-      if( c->coded_frame->key_frame )
-        pkt.flags |= AV_PKT_FLAG_KEY;
+    ret = avcodec_encode_video2(c, &pkt, ffmpeg_pict, &got_output);
+    if( ret >= 0 && got_output) {
+      pkt.pts = av_rescale_q( pkt.pts, c->time_base, video_st->time_base );
+      pkt.dts = av_rescale_q( pkt.dts, c->time_base, video_st->time_base );
+
       pkt.stream_index= video_st->index;
-      pkt.data = video_outbuf;
-      pkt.size = out_size;
 
             /* write the compressed frame in the media file */
       ret = av_interleaved_write_frame( oc, &pkt );
@@ -725,7 +744,7 @@
   vcodec = fmt->video_codec;
   acodec = fmt->audio_codec;
 
-  if( out_t == TYPE_FFMPEG && vcodec != CODEC_ID_NONE ) {
+  if( out_t == TYPE_FFMPEG && vcodec != AV_CODEC_ID_NONE ) {
 
     /* Find the video encoder requested by user selection */
     if( ffmpeg_vcodec != NULL && *ffmpeg_vcodec != 0 ) {
@@ -758,7 +777,7 @@
       return 1;
   }
 
-  if( snd_t == TYPE_FFMPEG && acodec != CODEC_ID_NONE ) {
+  if( snd_t == TYPE_FFMPEG && acodec != AV_CODEC_ID_NONE ) {
 
     /* Find the audio encoder requested by user selection */
     if( ffmpeg_acodec != NULL && *ffmpeg_acodec != 0 ) {
@@ -854,7 +873,7 @@
 
   if( !video_st ) return 0;
 
-  if( ( out_w != frm_w || out_h != frm_h || out_pix_fmt != PIX_FMT_YUV444P ) && 
+  if( ( out_w != frm_w || out_h != frm_h || out_pix_fmt != AV_PIX_FMT_YUV444P ) && 
 	( err = ffmpeg_rescale_video() ) ) return err;
   ffmpeg_add_frame_ffmpeg();
   printi( 2, "out_write_ffmpeg(): add frame\n" );
